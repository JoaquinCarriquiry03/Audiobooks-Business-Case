{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobooks business case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6496/2403072159.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_inputs = npz['inputs'].astype(np.float)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6496/2403072159.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_targets = npz['targets'].astype(np.int)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6496/2403072159.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6496/2403072159.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6496/2403072159.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6496/2403072159.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# let's create a temporary variable npz, where the three Audiobooks datasets will be stored.\n",
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "\n",
    "# Extract the inputs, and change them to float type.\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "# Targets must be int because of the sparse_categorical_crossentropy loss function, so they can be easily one-hot encoded\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# Load the validation data in the temporary variable and extract intputs and targets\n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "# Same with the test data\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 7ms/step - loss: 0.5768 - accuracy: 0.6689 - val_loss: 0.4286 - val_accuracy: 0.7562\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7647 - val_loss: 0.3777 - val_accuracy: 0.7942\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3873 - accuracy: 0.7936 - val_loss: 0.3578 - val_accuracy: 0.8031\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8002 - val_loss: 0.3467 - val_accuracy: 0.8143\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8041 - val_loss: 0.3453 - val_accuracy: 0.8009\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.7998 - val_loss: 0.3348 - val_accuracy: 0.8322\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8162 - val_loss: 0.3273 - val_accuracy: 0.8322\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8141 - val_loss: 0.3358 - val_accuracy: 0.8076\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8065 - val_loss: 0.3241 - val_accuracy: 0.8233\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8226 - val_loss: 0.3154 - val_accuracy: 0.8300\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8167 - val_loss: 0.3159 - val_accuracy: 0.8434\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8197 - val_loss: 0.3097 - val_accuracy: 0.8456\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.3458 - accuracy: 0.8022 - val_loss: 0.3178 - val_accuracy: 0.8166\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8246 - val_loss: 0.3172 - val_accuracy: 0.8188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dd2dc39e80>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the input and output sizes\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "# Use same hidden layer size for both hidden layers.\n",
    "hidden_layer_size = 50\n",
    "    \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='tanh'), # 2nd hidden layer\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 50\n",
    "max_epochs = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(train_inputs, \n",
    "          train_targets, \n",
    "          batch_size=batch_size,\n",
    "          epochs=max_epochs, # Epochs that we will train for (assuming there is not early stopping)\n",
    "          # Callbacks are functions called when a task is completed\n",
    "          # In this case, the task is to check if val_loss is increasing\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(validation_inputs, validation_targets), #I could also have splitted the data into to npz (train and test) \n",
    "          # and then make the split with validation_split\n",
    "          verbose = 1\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "After training on the training data and validating on the validation data, we test the final prediction power of our model by running it on the test dataset that the algorithm has NEVER seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8214\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.36. Test accuracy: 82.14%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
